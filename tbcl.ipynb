{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c325e439-1711-4fde-b235-d44737f0187f",
   "metadata": {},
   "source": [
    "# TBCL parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b408022-558b-48ca-bc62-65a95f308751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob, requests, io, urllib, json\n",
    "import pandas as pd\n",
    "import opencc\n",
    "\n",
    "pd.options.display.max_rows = 2000\n",
    "\n",
    "opencc_tw2s = opencc.OpenCC('tw2s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a21d089-8a49-4d85-9fe4-9074c378efd4",
   "metadata": {},
   "source": [
    "Download files from TBCL home page: https://coct.naer.edu.tw/download/tech_report/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4006e880-016e-4064-9c68-86db698c0ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "![[ ! -d downloads && -d ../downloads/tbcl ]] && ln -s ../downloads/tbcl downloads\n",
    "!mkdir -p downloads\n",
    "\n",
    "if not os.path.exists('downloads/.done'):\n",
    "    home_url = 'https://coct.naer.edu.tw/download/tech_report/'\n",
    "    resp = requests.get(home_url).content.decode('utf-8')\n",
    "    for url in sorted(re.findall('<a href=\"([^\"]+[.](?:xlsx|docx))\"', resp)):\n",
    "        url = os.path.join(home_url, url)\n",
    "        !cd downloads && wget -nc \"{url}\"\n",
    "    !chmod a-w downloads/*.xlsx; touch downloads/.done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789b97a5-dd71-4658-a388-a67edd7ac808",
   "metadata": {},
   "source": [
    "Symlinks for convenience and checksums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea40a07f-71a8-4786-8d2f-515c7ab61a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8bf588d24cb2f1ca37ce094110457619af5dc72e561fd7ed826bfa2489a58713  8000zhuyin_20160215.xlsx\n",
      "6b5e4845ac2220de985ff775da5c79a5b04e0055c4a4c7aedecb010c5c826706  8000zhuyin_20160316.xlsx\n",
      "7a0a7f719ecbdb77f01c3ba29059d74141924ef2732299e368ef922da0120c10  8000zhuyin_20161230.xlsx\n",
      "8da050a48af2ee39b7a693b689a5c318b0991780d3cadedef391b83bc60cc8b8  8000zhuyin_20170324.xlsx\n",
      "1c360c3f0addccb967b2d4d922be1afcb25a0f0791a8fc8858f4c01c6d1ab055  8000zhuyin_20180419.xlsx\n",
      "61f659c3ebdd64362879cd0dc5d85c8b3a28586439fc6941f30ab958bcd76f74  8000zhuyin_202204.xlsx\n",
      "e979ac6d953fb493502e54536b4b6ff534d06e3938700052aa15806d514efc92  8000zhuyin_202307.xlsx\n",
      "5e92ac49c5bb203e16fea29c53a2b2cb790033fb332a699c7689adde21528b8f  tbcl-affix.xlsx\n",
      "6329e2516c5dbe416b85f6a94d200ebe95493f24f233a63dc10d85aa257a088f  tbcl-chars.xlsx\n",
      "b6ce3747a06c8482ce5f4059689463de01a45d2b78707feb85917404ccffae62  tbcl-glossary.xlsx\n",
      "c587989cf89992d55d97a2f932289ef071648ca80339ccfaff7bb823914e5bcf  tbcl-grammar.xlsx\n",
      "cb16dcd262eb3e499273f972c9a3a404c40042a7def35631fc40b2a64dd50eb0  tbcl-words.xlsx\n",
      "b6ce3747a06c8482ce5f4059689463de01a45d2b78707feb85917404ccffae62  臺灣華語文能力基準基礎詞彙表_111-09-20.xlsx\n",
      "6329e2516c5dbe416b85f6a94d200ebe95493f24f233a63dc10d85aa257a088f  臺灣華語文能力基準漢字表_111-09-20.xlsx\n",
      "cb16dcd262eb3e499273f972c9a3a404c40042a7def35631fc40b2a64dd50eb0  臺灣華語文能力基準詞語表_111-11-14.xlsx\n",
      "c587989cf89992d55d97a2f932289ef071648ca80339ccfaff7bb823914e5bcf  臺灣華語文能力基準語法點表_112-01-04.xlsx\n",
      "5e92ac49c5bb203e16fea29c53a2b2cb790033fb332a699c7689adde21528b8f  臺灣華語文能力基準類詞綴表_111-09-20.xlsx\n"
     ]
    }
   ],
   "source": [
    "%%bash -e\n",
    "cd downloads\n",
    "chmod a-w *.xlsx *.ods *.pdf\n",
    "ln -sf '臺灣華語文能力基準詞語表_111-11-14.xlsx' tbcl-words.xlsx\n",
    "ln -sf '臺灣華語文能力基準詞語表_111-11-14.ods' tbcl-words.ods\n",
    "ln -sf '臺灣華語文能力基準漢字表_111-09-20.docx' tbcl-chars.docx\n",
    "ln -sf '臺灣華語文能力基準漢字表_111-09-20.xlsx' tbcl-chars.xlsx\n",
    "ln -sf '臺灣華語文能力基準類詞綴表_111-09-20.docx' tbcl-affix.docx\n",
    "ln -sf '臺灣華語文能力基準類詞綴表_111-09-20.xlsx' tbcl-affix.xlsx\n",
    "ln -sf '臺灣華語文能力基準語法點表_112-01-04.xlsx' tbcl-grammar.xlsx\n",
    "ln -sf '臺灣華語文能力基準語法點表_112-01-04.docx' tbcl-grammar.docx\n",
    "ln -sf '臺灣華語文能力基準基礎詞彙表_111-09-20.xlsx' tbcl-glossary.xlsx\n",
    "sha256sum *.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f2c66-8e66-4000-bf8e-06073ce37676",
   "metadata": {},
   "source": [
    "## Parse wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa4d891e-73db-4fdb-ada0-c428284143e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloads/tbcl-glossary.csv: 1518 rows\n"
     ]
    }
   ],
   "source": [
    "glossary_df = pd.read_excel('downloads/tbcl-glossary.xlsx').rename(columns={\n",
    "    '序號': 'ID',\n",
    "    '詞語': 'Traditional',\n",
    "    '注音': 'Zhuyin',\n",
    "    '漢拼': 'Pinyin',\n",
    "    '詞類/性質': 'POS',\n",
    "    '詞彙英譯': 'Meaning',\n",
    "    '語義/義項': 'Meaning2',\n",
    "    '用法-常用搭配詞': 'Compounds',\n",
    "    '例句': 'Examples',\n",
    "    '級別': 'Level',\n",
    "})\n",
    "assert list(glossary_df.ID - 1) == list(glossary_df.index)\n",
    "glossary_df['Level'] = glossary_df.Level.str.extract('^第([1-7][*]?)級$')[0]\n",
    "assert sum(glossary_df.Level.isnull()) == 0\n",
    "glossary_df.to_csv('downloads/tbcl-glossary.csv', index=False)\n",
    "print('downloads/tbcl-glossary.csv: %d rows' % len(glossary_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c49e9d65-3ca3-4ab5-b761-5d333b65f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opencc_tw2s = opencc.OpenCC('tw2s')\n",
    "\n",
    "# Character levels from Table of General Standard Chinese Characters for verification.\n",
    "tgh_level = pd.read_csv('../chars/tgh.csv').set_index('char').level.to_dict()\n",
    "\n",
    "# Convert to simplified characters + verify\n",
    "def to_simplified(trad):\n",
    "    simp = opencc_tw2s.convert(trad)\n",
    "    for x, y in ('擡抬', '砲炮', '牠它', '妳你', '姪侄', '瞇眯', '舖铺', '搥捶', '暱昵', '瑯琅'):\n",
    "        simp = simp.replace(x, y)\n",
    "    if '/' in simp and len(set(simp.split('/'))) == 1:\n",
    "        simp = simp.split('/')[0]\n",
    "    for c in simp:\n",
    "        assert c in tgh_level or c in '/(),吋拚徬祂', (trad, simp, c)\n",
    "    return simp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3779144e-46c4-4ebe-9b67-9954ef91d4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unjoined glossary vocab: 3月台/月臺 1英國 1臺灣/台灣 1還 3韓國 1美國 1中國 1車/車子 1日本 1法國 3亞洲 3歐洲 2瓶子/瓶瓶 1應該/應 3非洲 3美洲 2罐 3義大利 2德國\n",
      "tbcl.csv: 14425 terms\n"
     ]
    }
   ],
   "source": [
    "VARIANTS_EXC = {\n",
    "    ('姊姊/姐姐/姊/姐', 'jiějie/jiě'): [['姊姊','jiějie'], ['姐姐','jiějie'], ['姊','jiě'], ['姐','jiě']],\n",
    "    ('那/那裡/那裏/那兒', 'nà/nàlǐ/nàr'): [['那', 'nà'], ['那裡', 'nàlǐ'], ['那裏', 'nàlǐ'], ['那兒', 'nàr']],\n",
    "    ('這/這裡/這裏/這兒', 'zhè/zhèlǐ/zhèr'): [['這', 'zhè'], ['這裡', 'zhèlǐ'], ['這裏', 'zhèlǐ'], ['這兒', 'zhèr']],\n",
    "    ('手錶/手表/錶/表', 'shǒubiǎo/biǎo'): [['手錶', 'shǒubiǎo'], ['手表', 'shǒubiǎo'], ['錶', 'biǎo'], ['表', 'biǎo']],\n",
    "    ('新台幣/新臺幣/台幣/臺幣', 'xīntáibì/táibì'): [['新台幣', 'xīntáibì'], ['新臺幣', 'xīntáibì'], ['台幣', 'táibì'], ['臺幣', 'táibì']],\n",
    "    ('新台幣/新臺幣/台幣/臺幣', 'Xīntáibì/Táibì'): [['新台幣', 'Xīntáibì'], ['新臺幣', 'Xīntáibì'], ['台幣', 'Táibì'], ['臺幣', 'Táibì']],\n",
    "    ('慾望/欲望/慾', 'yùwàng/yù'): [['慾望', 'yùwàng'], ['欲望', 'yùwàng'], ['慾', 'yù']],\n",
    "    ('侄子/姪子/侄兒/姪兒', 'zhízi/zhír'): [['侄子', 'zhízi'], ['姪子', 'zhízi'], ['侄兒', 'zhír'], ['姪兒', 'zhír']],\n",
    "    ('嘴脣/嘴唇/脣/唇', 'zuǐchún/chún'): [['嘴脣', 'zuǐchún'], ['嘴唇', 'zuǐchún'], ['脣', 'chún'], ['唇', 'chún']],\n",
    "    ('沒(有)用', 'méi(yǒu)yòng'): [['沒用', 'méiyòng'], ['沒有用', 'méiyǒuyòng']],\n",
    "    ('一邊(兒)', 'yìbiān(r)'): [['一邊', 'yìbiān'], ['一邊兒', 'yìbiānr']],\n",
    "    ('一邊(兒)', 'yībiān(r)'): [['一邊', 'yībiān'], ['一邊兒', 'yībiānr']],\n",
    "    ('皺眉頭/皺眉', 'zhòuméi/zhòuméitóu'): [['皺眉頭', 'zhòuméitóu'], ['皺眉', 'zhòuméi']],\n",
    "}\n",
    "\n",
    "def get_variants(vocab, pinyin):\n",
    "    vocab = vocab.strip()\n",
    "    pinyin = re.sub(' */ *', '/', pinyin.strip())\n",
    "\n",
    "    ps = re.sub('[^()/]', '', pinyin)\n",
    "    vs = re.sub('[^()/]', '', vocab)\n",
    "    if ps == '' and vs == '':\n",
    "        return []\n",
    "\n",
    "    if (vocab, pinyin) in VARIANTS_EXC:\n",
    "        return VARIANTS_EXC[(vocab, pinyin)]\n",
    "\n",
    "    if vs == '' and ps:\n",
    "        assert set(ps) == {'/'}\n",
    "        return [[vocab, p.strip()] for p in pinyin.split('/')]\n",
    "\n",
    "    if vs and ps == '':\n",
    "        assert set(vs) == {'/'}\n",
    "        assert len(set(map(len, vocab.split('/')))) == 1, vocab  # all terms same length\n",
    "        return [[v, pinyin] for v in vocab.split('/')]\n",
    "\n",
    "    assert vs == ps and set(ps) == {'/'}, (vocab, pinyin)\n",
    "    return [[v.strip(), p.strip()] for (v, p) in zip(vocab.split('/'), pinyin.split('/'))]\n",
    "\n",
    "def get_variants_str(vocab, pinyin, moe):\n",
    "    variants = get_variants(vocab, pinyin)\n",
    "    if not variants:\n",
    "        return ''\n",
    "    arr = []\n",
    "    for (trad, py) in variants:\n",
    "        m = [x for x in json.loads(moe.replace(\"'\", '\"')) if x[0] == trad]\n",
    "        assert len(m) <= 1\n",
    "        if m:\n",
    "            assert m[0][0] == trad\n",
    "            m = ' '.join(m[0][1])\n",
    "        else:\n",
    "            m = ''\n",
    "        arr.append({\n",
    "            'Traditional': trad,\n",
    "            'Simplified': to_simplified(trad),\n",
    "            'Pinyin': normalize_pinyin(py, trad),\n",
    "            #'PinyinYB': py,\n",
    "            'MOE': m,\n",
    "        })\n",
    "    return json.dumps(arr, ensure_ascii=False)\n",
    "\n",
    "def fix_traditional(s):\n",
    "    # number suffixes for different pronunciations, +3 weird duplicate entries 空檔 道 來往\n",
    "    s = re.sub('[0-9]', '', s)\n",
    "    s = re.sub('／', '/', s)\n",
    "    assert re.match('^[\\u4E00-\\u9FFF/()]+$', s), (row, s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def normalize_pinyin(py, hz):\n",
    "    for x, y in ['ɑa', (' */ *', '/'), (r'\\s+', ' '), (' */$', ''), ('^/ *', '')]:\n",
    "        py = re.sub(x, y, py).strip()\n",
    "\n",
    "    # Pinyin spaces are not meaningul in TBCL lists, mostly just syllable spaces there.\n",
    "    # Remove to make more mergeable with TOCFL. Also no upper letters.\n",
    "    if ' ' in py:\n",
    "        assert py == py.lower() and \"'\" not in py, py\n",
    "        merged = ''\n",
    "        for part in py.split():\n",
    "            if merged and merged[-1] not in '/()' and part[0] in 'aeoāáǎàēéěèōóǒò':\n",
    "                merged += \"'\"\n",
    "            merged += part\n",
    "        py = merged\n",
    "        assert re.match(\"^[a-zāáǎàēéěèīíǐìōóǒòūúǔùüǘǚǜ/()']+$\", py), (py, repr(py))\n",
    "\n",
    "    if (py, hz) == ('búzhìyú', '不至於/不致於'): return 'bùzhìyú'\n",
    "    if (py, hz) == ('yíyìgūxíng', '一意孤行'): return 'yīyìgūxíng'\n",
    "    if (py, hz) == ('yìxīnyīyì', '一心一意'): return 'yīxīnyīyì'\n",
    "    if (py, hz) == ('yìxīnyíyì', '一心一意'): return 'yīxīnyīyì'\n",
    "\n",
    "    if '不' in hz and 'bú' in py:\n",
    "        assert hz.count('不') == py.count('bú') + py.count('bù'), (py, hz)\n",
    "        py = py.replace('bú', 'bù')\n",
    "\n",
    "    if '一' in hz and re.search('(yí|yì)', py):\n",
    "        assert hz.count('一') == py.count('yí') + py.count('yì'), (py, hz)\n",
    "        py = py.replace('yí', 'yī')\n",
    "        py = py.replace('yì', 'yī')\n",
    "\n",
    "    return py\n",
    "\n",
    "# Correct some errors in pinyin\n",
    "pinyin_corr_df = pd.read_csv('errata.csv', comment='#', dtype='str')\n",
    "\n",
    "def fix_pinyin(py, trad=''):\n",
    "    for row in pinyin_corr_df.itertuples():\n",
    "        if row.Pinyin == py and row.Traditional == trad:\n",
    "            py = row.Corrected\n",
    "    assert re.match('^[a-zāáǎàēéěèīíǐìōóǒòūúǔùüǘǚǜ/(), \\']+$', py.lower()), (py, repr(py))\n",
    "    return py\n",
    "\n",
    "\n",
    "df = pd.read_excel('downloads/tbcl-words.xlsx').rename(columns={\n",
    "    '序號': 'ID',\n",
    "    '詞語': 'Traditional',\n",
    "    '等別': 'Grade',\n",
    "    '級別': 'Level',\n",
    "    '情境': 'Context',\n",
    "    '書面字頻(每百萬字)': 'WFreq',\n",
    "    '口語字頻(每百萬字)': 'SFreq',\n",
    "    '簡編本系統號': 'MOE', # MOE dict IDs, https://dict.concised.moe.edu.tw/dictView.jsp?ID=.\n",
    "    '參考注音': 'Zhuyin',\n",
    "    '參考漢語拼音': 'PinyinYB'  # pinyin with tone change indication for 一 and 不\n",
    "})\n",
    "\n",
    "assert list(df.ID - 1) == list(df.index)\n",
    "df = df.drop(columns=['Grade', 'Zhuyin', 'Context'])\n",
    "\n",
    "df['Level'] = df.Level.str.extract('^第([1-7][*]?)級$')[0]\n",
    "assert sum(df.Level.isnull()) == 0\n",
    "\n",
    "df['glossary_key'] = (df.Level.str.slice(0, 1) + df.Traditional)\n",
    "glossary_df = glossary_df.fillna('')\n",
    "glossary_df['glossary_key'] = (glossary_df.Level.str.slice(0, 1) + glossary_df.Traditional)\n",
    "glossary_mp = glossary_df.assign(idx=glossary_df.index).groupby('glossary_key').idx.apply(list)\n",
    "\n",
    "df['Traditional'] = df.Traditional.map(fix_traditional)\n",
    "df.insert(2, 'Simplified', df.Traditional.map(to_simplified))\n",
    "df['Pinyin'] = [normalize_pinyin(row.PinyinYB, row.Traditional) for row in df.itertuples()]\n",
    "df['Pinyin'] = [fix_pinyin(row.Pinyin, row.Traditional) for row in df.itertuples()]\n",
    "del df['PinyinYB']\n",
    "df['Variants'] = [get_variants_str(row.Traditional, row.Pinyin, row.MOE) for row in df.itertuples()]\n",
    "\n",
    "for row in df.itertuples():\n",
    "    variants = [v['Traditional'] for v in json.loads(row.Variants)] if row.Variants else [row.Traditional]\n",
    "    moe = json.loads(row.MOE.replace(\"'\", '\"'))\n",
    "    if row.Variants or row.MOE == '[]':\n",
    "        for v, ids in moe:\n",
    "            assert v in variants\n",
    "        df.loc[row.Index, 'MOE'] = ''\n",
    "    else:\n",
    "        assert len(moe) == 1 and moe[0][0] == row.Traditional\n",
    "        df.loc[row.Index, 'MOE'] = ' '.join(moe[0][1])\n",
    "\n",
    "# Join with vocab_df\n",
    "for col in ['POS', 'Meaning', 'Compounds', 'Examples']:\n",
    "    df[col] = ''\n",
    "    for row in df.itertuples():\n",
    "        text = [glossary_df.loc[i, col] for i in glossary_mp.get(row.glossary_key, [])]\n",
    "        text = [s.strip() for s in text if s.strip()]\n",
    "        assert ' / ' not in ''.join(text), text\n",
    "        if not text: continue\n",
    "        dedup = []\n",
    "        for s in text:\n",
    "            if s not in dedup: dedup.append(s)\n",
    "        text = ' / '.join(dedup)\n",
    "        if col == 'POS':\n",
    "            text = text.replace(' ', '').strip()\n",
    "            text = text.replace('V/Ｖ', 'V')\n",
    "            text = text.replace('Phrase', 'Ph')\n",
    "            text = text.replace('詞組', 'Ph')\n",
    "            text = text.replace('Conj.', 'Conj')\n",
    "        elif col == 'Compounds':\n",
    "            text = text.replace(';', '')\n",
    "            text = text.replace(' / ', '，').split('，')\n",
    "            dedup = []\n",
    "            for s in text:\n",
    "                if s not in dedup: dedup.append(s)\n",
    "            text = '，'.join(text)\n",
    "            if text: text += '。'\n",
    "        for x, y in [(' *[(] +', ' ('), (' +[)]', ')'), (' +/ +', ' / ')]:\n",
    "            text = re.sub(x, y, text).strip()\n",
    "        assert '\\n' not in text\n",
    "        df.loc[row.Index, col] = text.strip()\n",
    "\n",
    "print('Unjoined glossary vocab: %s' % ' '.join(set(glossary_df.glossary_key) - set(df.glossary_key)))\n",
    "df = df.drop(columns=['glossary_key'])\n",
    "\n",
    "for col in ['WFreq', 'SFreq', 'MOE', 'Variants']:\n",
    "    assert col in df\n",
    "    oldcol = df[col]\n",
    "    df = df.drop(columns=[col])\n",
    "    df[col] = oldcol\n",
    "\n",
    "df.to_csv('tbcl.csv', index=False)\n",
    "print('tbcl.csv: %d terms' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78a3910f-b460-46d1-8f9f-480b94c78f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Traditional</th>\n",
       "      <th>Simplified</th>\n",
       "      <th>Level</th>\n",
       "      <th>Pinyin</th>\n",
       "      <th>POS</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Compounds</th>\n",
       "      <th>Examples</th>\n",
       "      <th>WFreq</th>\n",
       "      <th>SFreq</th>\n",
       "      <th>MOE</th>\n",
       "      <th>Variants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>愛</td>\n",
       "      <td>爱</td>\n",
       "      <td>1</td>\n",
       "      <td>ài</td>\n",
       "      <td>Vs/N</td>\n",
       "      <td>to love / love</td>\n",
       "      <td></td>\n",
       "      <td>我愛你。他很愛吃水果。 / 爸爸媽媽對孩子的愛很多。</td>\n",
       "      <td>535</td>\n",
       "      <td>681</td>\n",
       "      <td>39542</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>吧</td>\n",
       "      <td>吧</td>\n",
       "      <td>1</td>\n",
       "      <td>ba</td>\n",
       "      <td>Ptc</td>\n",
       "      <td>final particle (for confirming, request)</td>\n",
       "      <td>走吧。</td>\n",
       "      <td>你是從英國來的吧？我們一起去運動吧！</td>\n",
       "      <td>706</td>\n",
       "      <td>748</td>\n",
       "      <td>32 103</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>八</td>\n",
       "      <td>八</td>\n",
       "      <td>1</td>\n",
       "      <td>bā</td>\n",
       "      <td>N</td>\n",
       "      <td>eight</td>\n",
       "      <td>八個，八張，八年。</td>\n",
       "      <td>他買了八個包子。</td>\n",
       "      <td>214</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>爸爸/爸</td>\n",
       "      <td>爸爸/爸</td>\n",
       "      <td>1</td>\n",
       "      <td>bàba/bà</td>\n",
       "      <td>N</td>\n",
       "      <td>father</td>\n",
       "      <td></td>\n",
       "      <td>我爸爸喜歡看電影。爸爸，生日快樂。</td>\n",
       "      <td>226</td>\n",
       "      <td>806</td>\n",
       "      <td></td>\n",
       "      <td>[{\"Traditional\": \"爸爸\", \"Simplified\": \"爸爸\", \"Pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>百</td>\n",
       "      <td>百</td>\n",
       "      <td>1</td>\n",
       "      <td>bǎi</td>\n",
       "      <td>N</td>\n",
       "      <td>hundred</td>\n",
       "      <td>一百個人，三百六十五天，一百五十分鐘，一百塊。</td>\n",
       "      <td>一年有三百六十五天。</td>\n",
       "      <td>108</td>\n",
       "      <td>77</td>\n",
       "      <td>157 334</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Traditional Simplified Level   Pinyin   POS  \\\n",
       "0   1           愛          爱     1       ài  Vs/N   \n",
       "1   2           吧          吧     1       ba   Ptc   \n",
       "2   3           八          八     1       bā     N   \n",
       "3   4        爸爸/爸       爸爸/爸     1  bàba/bà     N   \n",
       "4   5           百          百     1      bǎi     N   \n",
       "\n",
       "                                    Meaning                Compounds  \\\n",
       "0                            to love / love                            \n",
       "1  final particle (for confirming, request)                      走吧。   \n",
       "2                                     eight                八個，八張，八年。   \n",
       "3                                    father                            \n",
       "4                                   hundred  一百個人，三百六十五天，一百五十分鐘，一百塊。   \n",
       "\n",
       "                     Examples  WFreq  SFreq      MOE  \\\n",
       "0  我愛你。他很愛吃水果。 / 爸爸媽媽對孩子的愛很多。    535    681    39542   \n",
       "1          你是從英國來的吧？我們一起去運動吧！    706    748   32 103   \n",
       "2                    他買了八個包子。    214    163        1   \n",
       "3           我爸爸喜歡看電影。爸爸，生日快樂。    226    806            \n",
       "4                  一年有三百六十五天。    108     77  157 334   \n",
       "\n",
       "                                            Variants  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2                                                     \n",
       "3  [{\"Traditional\": \"爸爸\", \"Simplified\": \"爸爸\", \"Pi...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1de529-7e4d-4afb-a775-5417ced153ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expanded/tbcl.csv: 14868 terms\n"
     ]
    }
   ],
   "source": [
    "# Generate version with variants expanded.\n",
    "\n",
    "expanded_rows = []\n",
    "for row in df.fillna('').to_dict(orient='records'):\n",
    "    variants = json.loads(row['Variants']) if row['Variants'] else [{}]\n",
    "    for variant in variants:\n",
    "        var = dict(row)\n",
    "        var.update(variant)\n",
    "        expanded_rows.append(var)\n",
    "\n",
    "expanded_df = pd.DataFrame(expanded_rows).drop(columns=['Variants'])\n",
    "expanded_df.to_csv('expanded/tbcl.csv', index=False)\n",
    "print('expanded/tbcl.csv: %d terms' % len(expanded_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48ca61c0-a6e9-4c44-bf7e-189ac0b98741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan users 1121374 Apr 15 00:19 pleco/tbcl-pleco.txt\n"
     ]
    }
   ],
   "source": [
    "EAC1_TAG = '\\uEAC1\\uEC00\\uEC00\\uECCC\\uEC99'  # tag color, #00cc99 green\n",
    "EAC1_EX  = '\\uEAC1\\uEC00\\uEC05\\uECAA\\uECFF'  # examples, #05aaff blue\n",
    "EAC1_HL  = '\\uEAC1\\uEC00\\uEC00\\uECCC\\uECCC'  # term highlight in examples, teal\n",
    "\n",
    "with open('pleco/tbcl-pleco.txt', 'w') as fout:\n",
    "    last_header = ''\n",
    "    for row in pd.read_csv('tbcl.csv', dtype='str').fillna('').to_dict(orient='records'):\n",
    "        header = f\"//TBCL/Level {row['Level']}\"\n",
    "        if header != last_header:\n",
    "            last_header = header\n",
    "            fout.write(header + '\\n')\n",
    "\n",
    "        variants = json.loads(row['Variants']) if row['Variants'] else [{}]\n",
    "        for variant in variants:\n",
    "            var = dict(row)\n",
    "            var.update(variant)\n",
    "            defn = ' '.join([\n",
    "                f\"{row['Traditional']} [{row['Pinyin']}]\\uEAB1\" if row['Variants'] else '',\n",
    "                f\"({row['POS']})\" if row.get('POS') else '',\n",
    "                f\"{row['Meaning']}\" if row.get('Meaning') else '',\n",
    "                f\"{EAC1_TAG}[TBCL{row['Level']}]\\uEAC2\",\n",
    "            ])\n",
    "            defn = re.sub(r'\\s+', ' ', defn).replace('\\uEAB1 ', '\\uEAB1').strip()\n",
    "            # Compounds and examples in light blue on separate lines\n",
    "            for ex in [var['Compounds'], var['Examples']]:\n",
    "                if not ex: continue\n",
    "                defn += (\n",
    "                    f'\\uEAB1{EAC1_EX}' +\n",
    "                    ex.replace(' / ', '\\uEAB1').replace(\n",
    "                        var['Traditional'],\n",
    "                        f\"\\uEAC2{EAC1_HL}{var['Traditional']}\\uEAC2{EAC1_EX}\"\n",
    "                    ) +\n",
    "                    '\\uEAC2'\n",
    "                )\n",
    "            key = f\"{var['Simplified']}[{var['Traditional']}]\\t{var['Pinyin']}\"\n",
    "            fout.write(f'{key}\\t{defn}\\n')\n",
    "\n",
    "!ls -l pleco/tbcl-pleco.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf03e3-7b61-483b-a1e0-49d072e4c3e6",
   "metadata": {},
   "source": [
    "## Convert other files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b88b5e6e-fdbf-4a0e-b41d-febf6e953c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tbcl-chars.csv: 3100 rows\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('downloads/tbcl-chars.xlsx').rename(columns={\n",
    "    '序號': 'ID',\n",
    "    '漢字': 'Traditional',\n",
    "    '等別': 'Grade',\n",
    "    '級別': 'Level',\n",
    "    '情境': 'Context',\n",
    "    '書面字頻（每百萬字）': 'WFreq',\n",
    "    '口語字頻（每百萬字）': 'SFreq',\n",
    "})\n",
    "\n",
    "assert list(df.ID - 1) == list(df.index)\n",
    "df = df.drop(columns=['Grade'])\n",
    "\n",
    "df['Level'] = df.Level.str.extract('^第([1-7][*]?)級$')[0]\n",
    "assert sum(df.Level.isnull()) == 0\n",
    "\n",
    "df['Traditional'] = df.Traditional.map(fix_traditional)\n",
    "df.to_csv('tbcl-chars.csv', index=False)\n",
    "print('tbcl-chars.csv: %d rows' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25c6d60d-52dc-4de6-bde3-833404500dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expanded/tbcl-chars.csv: 3133 rows\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for row in df.to_dict(orient='records'):\n",
    "    for ch in row['Traditional'].split('/'):\n",
    "        row['char'] = ch\n",
    "        rows.append(dict(row))\n",
    "\n",
    "expanded_df = pd.DataFrame(rows)[['char'] + list(df.columns)]\n",
    "expanded_df.to_csv('expanded/tbcl-chars.csv', index=False)\n",
    "print('expanded/tbcl-chars.csv: %d rows' % len(expanded_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6551c31f-f48a-4e2f-ae79-e38f5bf78775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tbcl-grammar.csv: 496 rows\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('downloads/tbcl-grammar.xlsx').rename(columns={\n",
    "    '序號': 'ID',\n",
    "    '語法點': 'Grammar',\n",
    "    '等別': 'Grade',\n",
    "    '級別': 'Level',\n",
    "    '例句': 'Example',\n",
    "})\n",
    "\n",
    "assert list(df.ID - 1) == list(df.index)\n",
    "df = df.drop(columns=['Grade'])\n",
    "\n",
    "def fix_grammar(text):\n",
    "    text = text.strip()\n",
    "    text = text.replace('......', '……')\n",
    "    return text\n",
    "\n",
    "df['Grammar'] = df['Grammar'].map(fix_grammar)\n",
    "df['Grammar'] = df.Grammar.str.replace('1', '¹')\n",
    "df['Grammar'] = df.Grammar.str.replace('2', '²')\n",
    "df['Grammar'] = df.Grammar.str.replace('3', '³')\n",
    "df['Grammar'] = df.Grammar.str.replace('4', '⁴')\n",
    "df['Grammar'] = df.Grammar.str.replace('5', '⁵')\n",
    "\n",
    "df['Level'] = df.Level.str.extract('^第([1-7][*]?)級$')[0]\n",
    "assert sum(df.Level.isnull()) == 0\n",
    "\n",
    "df.to_csv('tbcl-grammar.csv', index=False)\n",
    "print('tbcl-grammar.csv: %d rows' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d4821a7-b877-4413-8774-5cb2b3964920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tbcl-affix.csv: 73 rows\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('downloads/tbcl-affix.xlsx').rename(columns={\n",
    "    '序號': 'ID',\n",
    "    '類詞綴': 'Affix',\n",
    "    '語法點': 'Grammar',\n",
    "    '級別': 'Level',\n",
    "    '說明': 'Explanation',\n",
    "    '相關詞彙': 'Examples',\n",
    "})\n",
    "assert list(df.ID - 1) == list(df.index)\n",
    "\n",
    "df['Affix'] = df.Affix.str.replace('~', '～')\n",
    "df['Affix'] = df.Affix.str.replace('1', '¹')\n",
    "df['Affix'] = df.Affix.str.replace('2', '²')\n",
    "df['Affix'] = df.Affix.str.replace('3', '³')\n",
    "\n",
    "df['Level'] = df.Level.str.extract('^第([1-7][*]?)級$')[0]\n",
    "assert sum(df.Level.isnull()) == 0\n",
    "\n",
    "df.to_csv('tbcl-affix.csv', index=False)\n",
    "print('tbcl-affix.csv: %d rows' % len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde2681b-d30d-49b8-a902-78f2209a99be",
   "metadata": {},
   "source": [
    "## Readings check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9458efc4-51ad-4022-8513-61208da0ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tbcl.csv', dtype='str').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3d5db96-c576-4406-a032-c14abd57e367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1115', '開玩笑', '开玩笑', '3*', 'kāi wánxiào', 'Ph', 'to play a joke', '開一個玩笑，開別人玩笑。'] :\t 開玩笑 kāi wánxiào vs. ['kāiwánxiào', 'kāiwànxiào', 'kaiwánxiào', 'kaiwànxiào']\n",
      "['1137', '沒想到', '没想到', '3*', 'méi xiǎngdào', 'Ph', \"didn't expect\", ''] :\t 沒想到 méi xiǎngdào vs. ['mòxiangdao', 'mòxiangdào', 'mòxiǎngdao', 'mòxiǎngdào', 'méixiangdao', 'méixiangdào', 'méixiǎngdao', 'méixiǎngdào']\n",
      "['1160', '聖誕老人', '圣诞老人', '3*', 'Shèngdàn Lǎorén', 'N', 'Santa Claus', ''] :\t 聖誕老人 Shèngdàn Lǎorén vs. ['shèngdànlǎoren', 'shèngdànlǎorén', 'shèngdànlaoren', 'shèngdànlaorén']\n",
      "['1572', '阿嬤', '阿嬷', '4', 'āma', '', '', ''] :\t 阿嬤 āma vs. ['ēmo', 'ēmó', 'ēmā', 'āmo', 'āmó', 'āmā', 'àmo', 'àmó', 'àmā']\n",
      "['1726', '打招呼', '打招呼', '4', 'dǎ zhāohū', '', '', ''] :\t 打招呼 dǎ zhāohū vs. ['dázhāohu', 'dázhāohū', 'dazhāohu', 'dazhāohū', 'dǎzhāohu', 'dǎzhāohū']\n",
      "['1754', '拉肚子', '拉肚子', '4', 'lā dùzi', '', '', ''] :\t 拉肚子 lā dùzi vs. ['lādùzi', 'lādùzǐ', 'lādǔzi', 'lādǔzǐ', 'lāduzi', 'lāduzǐ', 'ladùzi', 'ladùzǐ', 'ladǔzi', 'ladǔzǐ']\n",
      "['2889', '尺寸', '尺寸', '5', 'chícun', '', '', ''] :\t 尺寸 chícun vs. ['chěcun', 'chěcùn', 'chǐcun', 'chǐcùn']\n",
      "['5158', '中華民國', '中华民国', '5', 'Zhōnghuá Mínguó', '', '', ''] :\t 中華民國 Zhōnghuá Mínguó vs. ['zhōnghuàmínguó', 'zhōnghuāmínguó', 'zhōnghuámínguó', 'zhònghuàmínguó', 'zhònghuāmínguó', 'zhònghuámínguó']\n",
      "['5329', '磅', '磅', '6', 'pāng', '', '', ''] :\t 磅 pāng vs. ['bàng', 'páng']\n",
      "['7155', '摟', '搂', '6', 'lóu', '', '', ''] :\t 摟 lóu vs. ['lōu', 'lǒu', 'lou']\n",
      "['7486', '舖', '铺', '6', 'pū', '', '', ''] :\t 舖 pū vs. ['pù']\n",
      "['7542', '齊', '齐', '6', 'zī', '', '', ''] :\t 齊 zī vs. ['qí']\n",
      "['9386', '縱', '纵', '6', 'zōng', '', '', ''] :\t 縱 zōng vs. ['zòng']\n",
      "['9387', '縱橫', '纵横', '6', 'zōnghéng', '', '', ''] :\t 縱橫 zōnghéng vs. ['zònghèng', 'zònghéng']\n",
      "['11583', '怔', '怔', '7', 'lèng', '', '', ''] :\t 怔 lèng vs. ['zhèng', 'zhēng']\n",
      "['12041', '澎湃', '澎湃', '7', 'pēngpài', '', '', ''] :\t 澎湃 pēngpài vs. ['péngpài']\n",
      "['12134', '舖陳', '铺陈', '7', 'pūchén', '', '', ''] :\t 舖陳 pūchén vs. ['pùchén']\n",
      "['12136', '舖路', '铺路', '7', 'pūlù', '', '', ''] :\t 舖路 pūlù vs. ['pùlu', 'pùlù']\n",
      "['12138', '舖設', '铺设', '7', 'pūshè', '', '', ''] :\t 舖設 pūshè vs. ['pùshe', 'pùshè']\n",
      "['12444', '三國演義', '三国演义', '7', 'Sānguó Yǎnyì', '', '', ''] :\t 三國演義 Sānguó Yǎnyì vs. ['sānguóyǎnyì', 'sānguóyǎnyi']\n",
      "['12667', '視網膜', '视网膜', '7', 'shìwǎngmò', '', '', ''] :\t 視網膜 shìwǎngmò vs. ['shìwǎngmó']\n",
      "['13307', '挾持', '挟持', '7', 'xiáchí', '', '', ''] :\t 挾持 xiáchí vs. ['jiāchi', 'jiāchí', 'xiéchi', 'xiéchí']\n",
      "['14109', '震懾', '震慑', '7', 'zhènzhé', '', '', ''] :\t 震懾 zhènzhé vs. ['zhènshè']\n"
     ]
    }
   ],
   "source": [
    "# Check readings\n",
    "if os.path.exists('../cedict/syllables.csv'):\n",
    "    readings_mp = {'一': set([]), '蹟': set(['jī']), '噢': set(['yǔ'])}\n",
    "    syll_df = pd.read_csv('../cedict/syllables.csv', dtype='str').fillna('')\n",
    "    for row in syll_df.itertuples():\n",
    "        readings_mp.setdefault(row.Traditional, set()).add(row.Pinyin.lower())\n",
    "        readings_mp.setdefault(row.Simplified, set()).add(row.Pinyin.lower())\n",
    "    readings_mp = {x: set([y.strip().lower() for y in readings_mp[x] if y.strip()]) for x in readings_mp}\n",
    "    readings_mp['不'] = set(['bù'])\n",
    "\n",
    "    def gen_readings(trad):\n",
    "        if trad == '':\n",
    "            yield ''\n",
    "        elif trad[0] not in readings_mp or ord(trad[0]) < 0x3E00:\n",
    "            yield from gen_readings(trad[1:])\n",
    "        else:\n",
    "            for x in readings_mp[trad[0]]:\n",
    "                for y in gen_readings(trad[1:]):\n",
    "                    yield x.lower() + (\"'\" if y and y[0] in 'aāáǎàeēéěèoōóǒò' else '') + y\n",
    "\n",
    "    for row in pd.read_csv('expanded/tbcl.csv', dtype='str').fillna('').itertuples():\n",
    "        trad, pinyin = row.Traditional,row.Pinyin\n",
    "        readings = list(gen_readings(trad))\n",
    "        if re.sub('', '', pinyin.lower()) not in readings:\n",
    "            print(list(row._asdict().values())[1:9], ':\\t', trad, pinyin, 'vs.', readings[:min(10, len(readings))])\n",
    "            #print('%s,%s,%s' % (row.Traditional, row.Pinyin, row.Pinyin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a3f32-3ccc-48f6-9a0a-2371d9b1763c",
   "metadata": {},
   "source": [
    "## Merge with CEDICT and generate anki deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41795481-ab01-4272-9439-f75802e697bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNTONE_MP = {\n",
    "    'a': 'a', 'ā': 'a', 'á': 'a', 'ǎ': 'a', 'à': 'a',\n",
    "    'e': 'e', 'ē': 'e', 'é': 'e', 'ě': 'e', 'è': 'e',\n",
    "    'o': 'o', 'ō': 'o', 'ó': 'o', 'ǒ': 'o', 'ò': 'o',\n",
    "    'i': 'i', 'ī': 'i', 'í': 'i', 'ǐ': 'i', 'ì': 'i',\n",
    "    'u': 'u', 'ū': 'u', 'ú': 'u', 'ǔ': 'u', 'ù': 'u',\n",
    "    'ü': 'ü', 'ǖ': 'ü', 'ǘ': 'ü', 'ǚ': 'ü', 'ǜ': 'ü'\n",
    "}\n",
    "\n",
    "# Check if pinyin from data (py1) matches cedict's (py2)\n",
    "# Optionally matching untoned vowels with tones if untone==True.\n",
    "def pinyin_matches(py1, py2, hz='', untone=False, yi=False, bu=False):\n",
    "    py1 = py1.lower()\n",
    "    py2 = py2.lower()\n",
    "    i, j = 0, 0\n",
    "    while i < len(py1) or j < len(py2):\n",
    "        a = ''\n",
    "        if i < len(py1):\n",
    "            a = py1[i]\n",
    "            if a in \"-',/() \":\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "        b = ''\n",
    "        if j < len(py2):\n",
    "            b = py2[j]\n",
    "            if b in \"-',/() \":\n",
    "                j += 1\n",
    "                continue\n",
    "\n",
    "        match = (a == b)\n",
    "        match |= untone and (UNTONE_MP.get(a, a) == b or a == UNTONE_MP.get(b, b))\n",
    "        if i > 0 and j > 0:\n",
    "            match |= yi and py1[i-1:i+1] in ['yí', 'yì'] and py2[j-1:j+1] == 'yī' and '一' in hz\n",
    "            match |= bu and py1[i-1:i+1] == 'bú' and py2[j-1:j+1] == 'bù' and '不' in hz\n",
    "\n",
    "        if match:\n",
    "            i += 1\n",
    "            j += 1\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    return i == len(py1) and j == len(py2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b57f33fc-8e25-4d6e-8405-57fd35745d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiguous simplified: {'ID': '85', 'Traditional': '妳', 'Simplified': '你', 'Level': '1', 'Pinyin': 'nǐ', 'POS': 'N', 'Meaning': 'you (female)', 'Compounds': '', 'Examples': '妳好，我是妳的同學。', 'WFreq': '463', 'SFreq': '1653', 'MOE': '12580', 'Variants': ''} ce {'奶', '你'} cc 妳\n",
      "Ambiguous simplified: {'ID': '853', 'Traditional': '乾', 'Simplified': '干', 'Level': '3', 'Pinyin': 'gān', 'POS': 'Vs/N', 'Meaning': 'dry / dried food', 'Compounds': '魚乾，肉乾，葡萄乾。', 'Examples': '今天早上洗的衣服，下午就乾了。 / 最近的天氣很乾，都沒有下雨。 / 我喜歡吃水果乾。', 'WFreq': '50', 'SFreq': '99', 'MOE': '16341 25228', 'Variants': ''} ce {'乾', '干'} cc 干\n",
      "Simplified diff: {'ID': '1482', 'Traditional': '牠', 'Simplified': '它', 'Level': '4', 'Pinyin': 'tā', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '343', 'SFreq': '659', 'MOE': '9925', 'Variants': ''} ce {'牠'} cc 牠\n",
      "Simplified diff: {'ID': '3615', 'Traditional': '藉口', 'Simplified': '借口', 'Level': '5', 'Pinyin': 'jièkǒu', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '32', 'SFreq': '10', 'MOE': '22281', 'Variants': ''} ce {'藉口'} cc 借口\n",
      "Simplified diff: {'ID': '4411', 'Traditional': '蒐集', 'Simplified': '搜集', 'Level': '5', 'Pinyin': 'sōují', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '30', 'SFreq': '19', 'MOE': '38841', 'Variants': ''} ce {'蒐集'} cc 搜集\n",
      "Ambiguous simplified: {'ID': '4690', 'Traditional': '閒', 'Simplified': '闲', 'Level': '5', 'Pinyin': 'xián', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '14', 'SFreq': '10', 'MOE': '27364', 'Variants': ''} ce {'閒', '闲'} cc 闲\n",
      "Ambiguous simplified: {'ID': '4962', 'Traditional': '於', 'Simplified': '于', 'Level': '5', 'Pinyin': 'yú', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '1026', 'SFreq': '269', 'MOE': '42632 44183', 'Variants': ''} ce {'于', '於'} cc 于\n",
      "Ambiguous simplified: {'ID': '4963', 'Traditional': '餘', 'Simplified': '余', 'Level': '5', 'Pinyin': 'yú', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '12', 'SFreq': '13', 'MOE': '44157', 'Variants': ''} ce {'余', '馀'} cc 余\n",
      "Simplified diff: {'ID': '5763', 'Traditional': '大夥', 'Simplified': '大伙', 'Level': '6', 'Pinyin': 'dàhuǒ', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '9', 'SFreq': '2', 'MOE': '', 'Variants': ''} ce {'大夥'} cc 大伙\n",
      "Ambiguous simplified: {'ID': '6512', 'Traditional': '夥', 'Simplified': '伙', 'Level': '6', 'Pinyin': 'huǒ', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '9', 'SFreq': '2', 'MOE': '20357', 'Variants': ''} ce {'夥', '伙'} cc 伙\n",
      "Ambiguous simplified: {'ID': '6754', 'Traditional': '藉由', 'Simplified': '借由', 'Level': '6', 'Pinyin': 'jièyóu', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '53', 'SFreq': '91', 'MOE': '45308', 'Variants': ''} ce {'藉由', '借由'} cc 借由\n",
      "Simplified diff: {'ID': '7462', 'Traditional': '憑藉', 'Simplified': '凭借', 'Level': '6', 'Pinyin': 'píngjiè', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '11', 'SFreq': '7', 'MOE': '3407', 'Variants': ''} ce {'凭藉'} cc 凭借\n",
      "Simplified diff: {'ID': '9046', 'Traditional': '原著', 'Simplified': '原着', 'Level': '6', 'Pinyin': 'yuánzhù', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '12', 'SFreq': '1', 'MOE': '44779', 'Variants': ''} ce {'原著'} cc 原着\n",
      "Ambiguous simplified: {'ID': '9281', 'Traditional': '著', 'Simplified': '着', 'Level': '6', 'Pinyin': 'zhù', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '4017', 'SFreq': '1760', 'MOE': '29560 29632 29651 30743 30817', 'Variants': ''} ce {'著', '着'} cc 着\n",
      "Ambiguous simplified: {'ID': '9347', 'Traditional': '著', 'Simplified': '着', 'Level': '6', 'Pinyin': 'zhuó', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '4017', 'SFreq': '1760', 'MOE': '29560 29632 29651 30743 30817', 'Variants': ''} ce {'著', '着'} cc 着\n",
      "Simplified diff: {'ID': '9372', 'Traditional': '諮商', 'Simplified': '咨商', 'Level': '6', 'Pinyin': 'zīshāng', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '24', 'SFreq': '4', 'MOE': '36665', 'Variants': ''} ce {'谘商'} cc 咨商\n",
      "Simplified diff: {'ID': '9375', 'Traditional': '諮詢', 'Simplified': '咨询', 'Level': '6', 'Pinyin': 'zīxún', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '20', 'SFreq': '7', 'MOE': '36664', 'Variants': ''} ce {'谘询'} cc 咨询\n",
      "Ambiguous simplified: {'ID': '9756', 'Traditional': '參', 'Simplified': '参', 'Level': '7', 'Pinyin': 'cān', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '5', 'SFreq': '2', 'MOE': '34675 38101 38188 38923', 'Variants': ''} ce {'参', '叁'} cc 参\n",
      "Simplified diff: {'ID': '10202', 'Traditional': '牴觸', 'Simplified': '抵触', 'Level': '7', 'Pinyin': 'dǐchù', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '3', 'SFreq': '1', 'MOE': '8390', 'Variants': ''} ce {'牴触'} cc 抵触\n",
      "Simplified diff: {'ID': '11369', 'Traditional': '鉅', 'Simplified': '巨', 'Level': '7', 'Pinyin': 'jù', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '5', 'SFreq': '3', 'MOE': '23993', 'Variants': ''} ce {'钜'} cc 巨\n",
      "Simplified diff: {'ID': '11373', 'Traditional': '鉅額', 'Simplified': '巨额', 'Level': '7', 'Pinyin': \"jù'é\", 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '3', 'SFreq': '1', 'MOE': '24000', 'Variants': ''} ce {'钜额'} cc 巨额\n",
      "Ambiguous simplified: {'ID': '12193', 'Traditional': '乾', 'Simplified': '干', 'Level': '7', 'Pinyin': 'qián', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '50', 'SFreq': '99', 'MOE': '16341 25228', 'Variants': ''} ce {'乾', '干'} cc 干\n",
      "Simplified diff: {'ID': '13054', 'Traditional': '土著', 'Simplified': '土着', 'Level': '7', 'Pinyin': 'tǔzhù', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '5', 'SFreq': '1', 'MOE': '11536', 'Variants': ''} ce {'土著'} cc 土着\n",
      "Ambiguous simplified: {'ID': '13571', 'Traditional': '薰', 'Simplified': '薰', 'Level': '7', 'Pinyin': 'xūn', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '4', 'SFreq': '8', 'MOE': '28690', 'Variants': ''} ce {'熏', '薰'} cc 薰\n",
      "Simplified diff: {'ID': '13581', 'Traditional': '薰陶', 'Simplified': '薰陶', 'Level': '7', 'Pinyin': 'xūntáo', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '4', 'SFreq': '5', 'MOE': '28692', 'Variants': ''} ce {'熏陶'} cc 薰陶\n",
      "Ambiguous simplified: {'ID': '14061', 'Traditional': '著', 'Simplified': '着', 'Level': '7', 'Pinyin': 'zháo', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '4017', 'SFreq': '1760', 'MOE': '29560 29632 29651 30743 30817', 'Variants': ''} ce {'著', '着'} cc 着\n",
      "Simplified diff: {'ID': '14321', 'Traditional': '卓著', 'Simplified': '卓着', 'Level': '7', 'Pinyin': 'zhuózhù', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': '', 'WFreq': '4', 'SFreq': '1', 'MOE': '30807', 'Variants': ''} ce {'卓著'} cc 卓着\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('tbcl.csv', dtype='str').fillna('')\n",
    "cedict_df = pd.read_csv('../cedict/cedict.csv')\n",
    "cedict_idx_mp = cedict_df.assign(idx=cedict_df.index).groupby('Traditional').idx.apply(list)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for row in df.fillna('').to_dict(orient='records'):\n",
    "    pinyin_set = set([row['Pinyin']])\n",
    "    matches = cedict_idx_mp.get(row['Traditional'], [])\n",
    "    if len(matches) == 0 and row['Variants']:\n",
    "        variants = json.loads(row['Variants']) if row['Variants'] else [{}]\n",
    "        for variant in variants:\n",
    "            matches.extend(cedict_idx_mp.get(variant['Traditional'], []))\n",
    "            pinyin_set.add(variant['Pinyin'])\n",
    "\n",
    "    matches = list(sorted(set(matches)))\n",
    "\n",
    "    flag = ''\n",
    "    if len(matches) != 0:\n",
    "        # Prioritize pronunciation matches, downpriorize names and variants\n",
    "        # TODO: match based on taiwanese pronunciation\n",
    "        if len(matches) > 1:\n",
    "            matches.sort(key=lambda i: (\n",
    "                -int(any(pinyin_matches(py, cedict_df.Pinyin[i], untone=False) for py in pinyin_set))\n",
    "                -int(any(pinyin_matches(py, cedict_df.Pinyin[i], untone=True) for py in pinyin_set))\n",
    "                +10*int(re.match('^variant', cedict_df.Definitions[i]) is not None)\n",
    "                +100*int(cedict_df.Pinyin[i][0].isupper())\n",
    "                +100*int(re.match('^surname', cedict_df.Definitions[i]) is not None)\n",
    "            ))\n",
    "\n",
    "        ce_simp = set([cedict_df.Simplified[i] for i in matches])\n",
    "        cc_simp = opencc_tw2s.convert(row['Traditional'])\n",
    "        if not row['Variants'] and ce_simp:\n",
    "            if row['Simplified'] not in ce_simp:\n",
    "                print('Simplified diff:', row, 'ce', ce_simp, 'cc', cc_simp)\n",
    "            if len(ce_simp) > 1:\n",
    "                print('Ambiguous simplified:', row, 'ce', ce_simp, 'cc', cc_simp)\n",
    "\n",
    "        defs = []\n",
    "        for i in matches:\n",
    "            py1 = list(pinyin_set)[0] if len(pinyin_set) == 1 else ''\n",
    "            defn = cedict_df.Definitions[i]\n",
    "            #if cedict_df.Pinyin[i][0].isupper() and len(defs) == 0 and (len(py1) == 0 or not py1[0].isupper()):\n",
    "            #    print('%s,%s,%s' % (row['Traditional'], py1, py1))\n",
    "            defn = re.sub(r'/CL:個\\|个\\[ge4\\](|/.*)$', r'\\1', defn)  # uninformative\n",
    "            if row['Variants']:\n",
    "                defn = '%s [%s] %s' % (cedict_df.Traditional[i], cedict_df.Pinyin[i], defn)\n",
    "            elif not pinyin_matches(py1, cedict_df.Pinyin[i], untone=False):\n",
    "                defn = '[%s] %s' % (cedict_df.Pinyin[i], defn)\n",
    "            defs.append(defn)\n",
    "\n",
    "        if not row['Meaning']:\n",
    "            row['Meaning'] = '<br> '.join(defs)\n",
    "\n",
    "    #row['Flag'] = flag\n",
    "    rows.append(row)\n",
    "\n",
    "merged_df = pd.DataFrame(rows)\n",
    "#merged_df = merged_df.drop(columns=['Compounds', 'Examples'])\n",
    "merged_df.to_csv('tbcl-cedict.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3994829-978e-4d2c-9779-71449ae11558",
   "metadata": {},
   "source": [
    "*Taiwan TBCL wordlist (Traditional)*\n",
    "\n",
    "TBCL (Taiwan Benchmarks for the Chinese Language) wordlist, 14425 words over 7 levels. Parsed from official excel sheets from [TBCL](https://coct.naer.edu.tw/TBCL/) website, including definitions/examples for about 1500 lower level words that they provide. CC-CEDICT definitions for the rest.\n",
    "\n",
    "Pinyin normalized to not indicate tone changes for 一 and 不 for ease of joining with other data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97300889-3880-45ed-abeb-e228f1f81460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan users 156062443 Apr 15 00:19 tbcl.apkg\n"
     ]
    }
   ],
   "source": [
    "import genanki, shutil\n",
    "\n",
    "df = merged_df.copy().fillna('')\n",
    "\n",
    "!mkdir -p downloads/media\n",
    "!cp -f ../downloads/fonts/MoeStandardKai.ttf downloads/media/_MoeStandardKai.ttf\n",
    "\n",
    "cols = ['ID', 'Traditional', 'Simplified', 'Pinyin', 'Level',\n",
    "        'POS', 'Meaning', 'Compounds', 'Examples', 'Variants']\n",
    "\n",
    "model = genanki.Model(\n",
    "    1698579990,\n",
    "    'TBCL',\n",
    "    fields=[{'name': c} for c in cols],\n",
    "    templates=[{\n",
    "        'name': 'TBCL',\n",
    "        'qfmt': open('../dangdai/dangdai-qfmt.html').read().replace('{{ID}}', 'TBCL L{{Level}}'),\n",
    "        # TODO fix template\n",
    "        'afmt': '''{{FrontSide}}\n",
    "<hr id=answer>\n",
    "<div lang=\"en\"><span id=\"ddzw-pinyin\">{{Pinyin}}</span></div><br>\n",
    "<div lang=\"en\">{{#POS}}({{POS}}) {{/POS}}{{Meaning}}</div><br>\n",
    "<div>{{#Compounds}}{{Compounds}}<br>{{/Compounds}}{{Examples}}</div><br>\n",
    "''' + re.sub('^.*<script>', '<script>', open('../dangdai/dangdai-afmt.html').read(), flags=re.M).replace(\n",
    "            'if (pinyinEl && hanziEl)',\n",
    "            'if (pinyinEl && hanziEl {{#Variants}}&& false{{/Variants}})'),\n",
    "    }],\n",
    "    css=open('../dangdai/dangdai.css').read(),\n",
    ")\n",
    "\n",
    "deck = genanki.Deck(1698579991, name='tbcl')\n",
    "\n",
    "for row in df.reset_index().to_dict(orient='records'):\n",
    "    note = genanki.Note(\n",
    "        model=model,\n",
    "        fields=[row[c] for c in cols],\n",
    "        guid=genanki.guid_for('tbcl', row['ID']),\n",
    "        tags=['L%s' % row['Level'][0]],\n",
    "    )\n",
    "    deck.add_note(note)\n",
    "\n",
    "!rm -f tbcl.apkg\n",
    "genanki.Package(deck, media_files=glob.glob('downloads/media/*')).write_to_file('tbcl.apkg')\n",
    "!ls -l tbcl.apkg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
